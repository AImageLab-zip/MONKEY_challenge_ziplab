{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5abbf4-91c4-495d-a0e1-5791544d3ba4",
   "metadata": {},
   "source": [
    "# Step 3: Creating the model inference script\n",
    "To submit your algorithm to the challenge, you need to create an inference docker container. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84728b1-6166-400b-8ff7-312fc87145bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous exec path: /workspace/source/notebooks\n",
      "Current exec path: /workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(f\"Previous exec path: {os.getcwd()}\")\n",
    "# move two level up\n",
    "os.chdir(\"../../\")\n",
    "print(f\"Current exec path: {os.getcwd()}\")\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import creationism\n",
    "from tqdm import tqdm\n",
    "\n",
    "from wholeslidedata.interoperability.asap.annotationwriter import write_point_set\n",
    "from wholeslidedata.image.wholeslideimage import WholeSlideImage\n",
    "from wholeslidedata.iterators import create_patch_iterator, PatchConfiguration\n",
    "from wholeslidedata.annotation.labels import Label\n",
    "\n",
    "from source.utils.wsdetectron2 import Detectron2DetectionPredictor\n",
    "from source.utils.structures import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24b90e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\n"
     ]
    }
   ],
   "source": [
    "# set up path one level above\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fcf108-70f5-4339-be0e-358e07909d3a",
   "metadata": {},
   "source": [
    "Setting up the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f91aee-5195-4366-9c2d-73542eb65e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch GPU available: True\n",
      "./data/monkey-data/images/pas-cpg/A_P000002_PAS_CPG.tif ./data/monkey-data/images/tissue-masks/A_P000002_mask.tif\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"./data/monkey-data/images/pas-cpg/A_P000002_PAS_CPG.tif\"\n",
    "mask_path = r\"./data/monkey-data/images/tissue-masks/A_P000002_mask.tif\"\n",
    "output_path = r\"./outputs/results\"\n",
    "if not (os.path.isdir(output_path)):\n",
    "    os.mkdir(output_path)\n",
    "json_filename_immune_cells = \"detected-inflammatory-cells.json\"\n",
    "json_filename_lymphocytes = \"detected-lymphocytes.json\"\n",
    "json_filename_monocytes = \"detected-monocytes.json\"\n",
    "\n",
    "print(f\"Pytorch GPU available: {torch.cuda.is_available()}\")\n",
    "print(image_path, mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1031a-b590-4917-86e1-768a31a71147",
   "metadata": {},
   "source": [
    "Defining patch configuration for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f99bab4-b6e2-45fc-9b5d-1ff12437b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_shape = (128, 128, 3)\n",
    "spacings = (0.5,)\n",
    "overlap = (0, 0)\n",
    "offset = (0, 0)\n",
    "center = False\n",
    "\n",
    "patch_configuration = PatchConfiguration(\n",
    "    patch_shape=patch_shape,\n",
    "    spacings=spacings,\n",
    "    overlap=overlap,\n",
    "    offset=offset,\n",
    "    center=center,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86930aa-5184-46c1-b9c0-13e723d56bdb",
   "metadata": {},
   "source": [
    "Loading the saved model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4122d05f-8153-4dde-9abf-362b8311217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detectron2DetectionPredictor(\n",
    "    output_dir=output_path,\n",
    "    threshold=0.1,\n",
    "    nms_threshold=0.2,\n",
    "    weight_root=\"./outputs/model_final.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4167cee-bdb9-4f8a-9103-e97c9ce31ac0",
   "metadata": {},
   "source": [
    "Creating a patch iterator using the roi mask and sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b3e546-321f-4797-8649-cceeed9a5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = create_patch_iterator(\n",
    "    image_path=image_path,\n",
    "    mask_path=mask_path,\n",
    "    patch_configuration=patch_configuration,\n",
    "    cpus=4,\n",
    "    backend=\"asap\",\n",
    ")  # was backend='asap'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9487fdd-67d7-4d1a-aff0-fbff7bb63b2e",
   "metadata": {},
   "source": [
    "Some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb0e923-9a7d-4cca-924f-f6383a9cddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def px_to_mm(px: int, spacing: float):\n",
    "    return px * spacing / 1000\n",
    "\n",
    "\n",
    "def to_wsd(points, label: str = \"lymphocyte\"):\n",
    "    if label == \"lymphocyte\":\n",
    "        label = Label(\"lymphocyte\", 1, color=\"red\")\n",
    "    elif label == \"monocyte\":\n",
    "        label = Label(\"monocyte\", 2, color=\"green\")\n",
    "    else:\n",
    "        label = Label(\"inflammatory-cell\", 3, color=\"blue\")\n",
    "    \"\"\"Convert list of coordinates into WSD points\"\"\"\n",
    "    new_points = []\n",
    "    for i, point in enumerate(points):\n",
    "        p = Point(\n",
    "            index=i,\n",
    "            label=label,\n",
    "            coordinates=[point],\n",
    "        )\n",
    "        new_points.append(p)\n",
    "    return new_points\n",
    "\n",
    "\n",
    "def write_json_file(*, location, content):\n",
    "    # Writes a json file\n",
    "    with open(location, \"w\") as f:\n",
    "        f.write(json.dumps(content, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6511c62-3c21-4f7d-8dc7-2246459c8ec7",
   "metadata": {},
   "source": [
    "Run inference on an image with loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9f7e6e3-5bb5-4dd7-a9d4-7097700691de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(iterator, predictor, spacing, image_path, output_path):\n",
    "    from copy import deepcopy\n",
    "\n",
    "    print(\"predicting...\")\n",
    "\n",
    "    SPACING_CONST = 0.24199951445730394\n",
    "\n",
    "    json_filename_immune_cells = \"detected-inflammatory-cells.json\"\n",
    "    json_filename_lymphocytes = \"detected-lymphocytes.json\"\n",
    "    json_filename_monocytes = \"detected-monocytes.json\"\n",
    "\n",
    "    output_dict = {\n",
    "        \"name\": \"\",\n",
    "        \"type\": \"Multiple points\",\n",
    "        \"version\": {\"major\": 1, \"minor\": 0},\n",
    "        \"points\": [],\n",
    "    }\n",
    "\n",
    "    output_dict_immune_cells = deepcopy(output_dict)\n",
    "    output_dict_lymphocytes = deepcopy(output_dict)\n",
    "    output_dict_monocytes = deepcopy(output_dict)\n",
    "\n",
    "    output_dict_immune_cells[\"name\"] = \"inflammatory-cells\"\n",
    "    output_dict_lymphocytes[\"name\"] = \"lymphocytes\"\n",
    "    output_dict_monocytes[\"name\"] = \"monocytes\"\n",
    "\n",
    "    annotations_immune_cells = []\n",
    "    annotations_lymphocytes = []\n",
    "    annotations_monocytes = []\n",
    "\n",
    "    counter_immune_cells = 0\n",
    "    counter_lymphocytes = 0\n",
    "    counter_monocytes = 0\n",
    "\n",
    "    # NOTE / TODO: i used a different spacing for the image (0.24199951445730394), so we need to be shure how this works...\n",
    "    spacing_min = (\n",
    "        0.25  # was used in the original code to edit the annotations to bounding boxes\n",
    "    )\n",
    "    ratio = spacing / spacing_min\n",
    "    with WholeSlideImage(image_path) as wsi:\n",
    "        spacing = wsi.get_real_spacing(spacing_min)\n",
    "        print(f\"Spacing: {spacing} - Spacing const: {SPACING_CONST} - ratio: {ratio}\")\n",
    "\n",
    "    for x_batch, y_batch, info in tqdm(iterator):\n",
    "        x_batch = x_batch.squeeze(0)\n",
    "        y_batch = y_batch.squeeze(0)\n",
    "\n",
    "        predictions = predictor.predict_on_batch(x_batch)\n",
    "        for idx, prediction in enumerate(predictions):\n",
    "            c = info[\"x\"]\n",
    "            r = info[\"y\"]\n",
    "\n",
    "            for detections in prediction:\n",
    "                x, y, label, confidence = detections.values()\n",
    "                # print(f\"Detected {label} at {x}, {y} with confidence {confidence}\")\n",
    "\n",
    "                if x == 128 or y == 128:\n",
    "                    continue\n",
    "\n",
    "                if y_batch[idx][y][x] == 0:\n",
    "                    continue\n",
    "\n",
    "                x = x * ratio + c  # x is in spacing = 0.5 but c is in spacing = 0.25\n",
    "                y = y * ratio + r\n",
    "\n",
    "                prediction_record_immune_cells = {\n",
    "                    \"name\": \"Point \" + str(counter_immune_cells),\n",
    "                    \"point\": [\n",
    "                        px_to_mm(x, spacing),\n",
    "                        px_to_mm(y, spacing),\n",
    "                        SPACING_CONST,\n",
    "                    ],\n",
    "                    \"probability\": confidence,\n",
    "                }\n",
    "                output_dict_immune_cells[\"points\"].append(\n",
    "                    prediction_record_immune_cells\n",
    "                )\n",
    "                annotations_immune_cells.append((x, y))\n",
    "                counter_immune_cells += 1\n",
    "\n",
    "                if label == \"lymphocyte\":  # lymphocyte\n",
    "                    prediction_record_lymphocytes = {\n",
    "                        \"name\": \"Point \" + str(counter_lymphocytes),\n",
    "                        \"point\": [\n",
    "                            px_to_mm(x, spacing),\n",
    "                            px_to_mm(y, spacing),\n",
    "                            SPACING_CONST,\n",
    "                        ],\n",
    "                        \"probability\": confidence,\n",
    "                    }\n",
    "                    output_dict_lymphocytes[\"points\"].append(\n",
    "                        prediction_record_lymphocytes\n",
    "                    )\n",
    "                    annotations_lymphocytes.append((x, y))\n",
    "                    counter_lymphocytes += 1\n",
    "\n",
    "                elif label == \"monocyte\":  # monocyte\n",
    "                    prediction_record_monocytes = {\n",
    "                        \"name\": \"Point \" + str(counter_monocytes),\n",
    "                        \"point\": [\n",
    "                            px_to_mm(x, spacing),\n",
    "                            px_to_mm(y, spacing),\n",
    "                            SPACING_CONST,\n",
    "                        ],\n",
    "                        \"probability\": confidence,\n",
    "                    }\n",
    "                    output_dict_monocytes[\"points\"].append(prediction_record_monocytes)\n",
    "                    annotations_monocytes.append((x, y))\n",
    "                    counter_monocytes += 1\n",
    "\n",
    "                else:\n",
    "                    print(\"Unknown label\")\n",
    "                    continue\n",
    "\n",
    "    print(f\"Predicted {len(annotations_immune_cells)} points\")\n",
    "    print(\"saving predictions...\")\n",
    "\n",
    "    # for i, points in enumerate(annotations):\n",
    "    #     print(f\"Annotation {i}: {points}\")\n",
    "\n",
    "    # saving json file immune cells\n",
    "    output_path_json_immune_cells = os.path.join(\n",
    "        output_path, json_filename_immune_cells\n",
    "    )\n",
    "    write_json_file(\n",
    "        location=output_path_json_immune_cells, content=output_dict_immune_cells\n",
    "    )\n",
    "\n",
    "    # saving json file lymphocytes\n",
    "    output_path_json_lyphocytes = os.path.join(output_path, json_filename_lymphocytes)\n",
    "    write_json_file(\n",
    "        location=output_path_json_lyphocytes, content=output_dict_lymphocytes\n",
    "    )\n",
    "\n",
    "    # saving json file monocytes\n",
    "    output_path_json_monocytes = os.path.join(output_path, json_filename_monocytes)\n",
    "    write_json_file(location=output_path_json_monocytes, content=output_dict_monocytes)\n",
    "\n",
    "    # #TODO: bugged code, they had the same problem and even downgrading shapely didn't work :(\n",
    "    # # saving xml file\n",
    "    # annotations_wsd = to_wsd(annotations_immune_cells, label=\"inflammatory-cell\")\n",
    "    # xml_filename = 'points_results.xml'\n",
    "    # output_path_xml = os.path.join(output_path,xml_filename)\n",
    "    # write_point_set(\n",
    "    #     annotations_wsd,\n",
    "    #     output_path_xml,\n",
    "    #     label_color=\"blue\",\n",
    "    # )\n",
    "\n",
    "    print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf43390-c419-4b8a-9f5a-104cb8040592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n",
      "Spacing: 0.24199951445730394 - Spacing const: 0.24199951445730394 - ratio: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/379 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  max_size = (max_size + (stride - 1)) // stride * stride\n",
      "/venv/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 379/379 [00:42<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 14925 points\n",
      "saving predictions...\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "inference(\n",
    "    iterator=iterator,\n",
    "    predictor=model,\n",
    "    spacing=spacings[0],\n",
    "    image_path=image_path,\n",
    "    output_path=output_path,\n",
    ")\n",
    "\n",
    "iterator.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
